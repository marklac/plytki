{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50af4361-606a-4c12-a3f7-2aa5b9518e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, subprocess, time, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from qiskit.circuit.library import ZZFeatureMap, TwoLocal\n",
    "from qiskit_aer.primitives import Estimator\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
    "from qiskit_machine_learning.optimizers import COBYLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c78edc3-b743-49e8-80db-5037ebec5c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Parametry do łatwej zmiany =====\n",
    "data_path   = \"countsAll_fixed_07_07_23.csv\"  # ścieżka do pliku z danymi\n",
    "sep         = \"\\t\"                            # separator (w Twoim pliku jest tab)\n",
    "n_components_pca = 4                          # liczba komponentów PCA = liczba kubitów\n",
    "test_size   = 0.20                            # ułamek danych do testu\n",
    "random_state = 42                             # ziarno losowe\n",
    "maxiter     = 200                             # iteracje optymalizatora\n",
    "entanglement = \"linear\"                       # \"linear\" | \"full\" | lista par\n",
    "reps_feature = 2                              # głębokość feature map\n",
    "reps_ansatz  = 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb6dde66-9f4b-40d4-ae98-e86e371e4313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_labels_from_columns(columns):\n",
    "    \"\"\"\n",
    "    Etykieta 0: próbki zdrowe (zawierają '-HD-' w nazwie),\n",
    "    Etykieta 1: próbki z RNA nowotworowym (pozostałe).\n",
    "    \"\"\"\n",
    "    return np.array([0 if \"-HD-\" in c else 1 for c in columns], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "513ba33b-095e-4f47-b34f-939ad9455e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vqc_qnn(num_features: int):\n",
    "    \"\"\"\n",
    "    Buduje EstimatorQNN z ZZFeatureMap i TwoLocal (VQC).\n",
    "    \"\"\"\n",
    "    feature_map = ZZFeatureMap(feature_dimension=num_features, reps=reps_feature, entanglement=entanglement)\n",
    "    ansatz = TwoLocal(\n",
    "        num_qubits=num_features,\n",
    "        reps=reps_ansatz,\n",
    "        rotation_blocks=[\"ry\", \"rz\"],\n",
    "        entanglement_blocks=\"cz\",\n",
    "        entanglement=entanglement,\n",
    "    )\n",
    "    estimator = Estimator()  # Aer backend\n",
    "\n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=feature_map.compose(ansatz),\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters,\n",
    "        estimator=estimator,\n",
    "    )\n",
    "\n",
    "    optimizer = COBYLA(maxiter=maxiter)   # tutaj ustawiamy maxiter\n",
    "    clf = NeuralNetworkClassifier(\n",
    "        neural_network=qnn,\n",
    "        optimizer=optimizer,\n",
    "        one_hot=False,    # bo etykiety to 0/1\n",
    "    )\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26f700f6-2e38-4bd1-b9be-dd1721e579d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wczytywanie danych...\n"
     ]
    }
   ],
   "source": [
    "# ===== 1) Wczytanie i przygotowanie danych =====\n",
    "print(\"Wczytywanie danych...\")\n",
    "df = pd.read_csv(data_path, sep=sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fafe7324-5b13-4cce-8cd6-158e283a719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba cech (genów): 5346, liczba próbek: 2351\n",
      "Klasy: 0 (zdrowe) = 280, 1 (nowotworowe) = 2071\n"
     ]
    }
   ],
   "source": [
    "# Wiersze = geny, kolumny = próbki; transpozycja => próbki x geny\n",
    "X = df.T\n",
    "y = infer_labels_from_columns(X.index.tolist())\n",
    "\n",
    "print(f\"Liczba cech (genów): {X.shape[1]}, liczba próbek: {X.shape[0]}\")\n",
    "print(f\"Klasy: 0 (zdrowe) = {(y==0).sum()}, 1 (nowotworowe) = {(y==1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2eb4795-a2ff-4dc8-bdc5-77d0eb30501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standaryzacja i PCA (redukcja do n_components_pca = liczby kubitów)\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_scaled = scaler.fit_transform(X.values)\n",
    "\n",
    "pca = PCA(n_components=n_components_pca, random_state=random_state)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pca, y, test_size=test_size, stratify=y, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf7ec1a5-787e-4c0d-8ed5-aa63463aecba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] LogisticRegression+PCA=4: accuracy=0.6879, czas=0.03s\n"
     ]
    }
   ],
   "source": [
    "# ===== 2) Szybki klasyczny baseline (LogReg + PCA) =====\n",
    "t0 = time.time()\n",
    "logreg = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_lr = logreg.predict(X_test)\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "t_lr = time.time() - t0\n",
    "print(f\"[Baseline] LogisticRegression+PCA={n_components_pca}: accuracy={acc_lr:.4f}, czas={t_lr:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8d7fcf-d555-4c47-9090-d849dabb3e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trenowanie VQC (EstimatorQNN)...\n"
     ]
    }
   ],
   "source": [
    "# ===== 3) VQC (EstimatorQNN) =====\n",
    "print(\"Trenowanie VQC (EstimatorQNN)...\")\n",
    "t0 = time.time()\n",
    "vqc = build_vqc_qnn(num_features=n_components_pca)\n",
    "vqc.fit(X_train, y_train)\n",
    "y_pred_vqc = vqc.predict(X_test)\n",
    "acc_vqc = accuracy_score(y_test, y_pred_vqc)\n",
    "t_vqc = time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85115a84-c661-4895-8c2b-126030bdb6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== WYNIKI ===\")\n",
    "print(f\"VQC (ZZFeatureMap + TwoLocal) | PCA={n_components_pca} | reps_fm={reps_feature} | reps_ansatz={reps_ansatz}\")\n",
    "print(f\"Accuracy (test): {acc_vqc:.4f}\")\n",
    "print(f\"Czas wykonania (s): {t_vqc:.2f}\")\n",
    "\n",
    "print(\"\\n[Porównanie] Baseline vs VQC\")\n",
    "print(f\"- Baseline  : acc={acc_lr:.4f}, czas={t_lr:.2f}s\")\n",
    "print(f\"- VQC       : acc={acc_vqc:.4f}, czas={t_vqc:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95936077-4cac-463a-b583-00952b6ca57e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
